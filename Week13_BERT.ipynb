{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (4.49.0)\n",
      "Requirement already satisfied: requests in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: packaging in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (4.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\islam\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: click in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sacremoses->transformers) (8.1.3)\n",
      "Requirement already satisfied: six in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\islam\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sacremoses->transformers) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\islam\\appdata\\roaming\\python\\python37\\site-packages (from click->sacremoses->transformers) (0.4.4)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BERT is a pretrained model that expects that the input data is in a specific format.\n",
    "- The data format is as follows:\n",
    "1. [SEP] is a special token that is used to mark the end of a sentence or the seperation between two sentences.\n",
    "2. [CLS] is a special token that marks the beginning of the text. \n",
    "3. Tokens must conform with the fixed vocab. used in BERT\n",
    "4. TokenIDs should be retrieved from BertTokenizer\n",
    "5. MaskIDs which mark tokens vs padding elements\n",
    "6. SegmentID represents different sentences.\n",
    "7. Position Embeddings used to show token position within the sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"The quick brown fox jumping over the lazy dog. The dog barked at the fox extract embeddings.\",\n",
    "    \"The fox ran away quickly.\",\n",
    "    \"The dog is lazy.\",\n",
    "    \"The fox is cunning.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] The quick brown fox jumping over the lazy dog [SEP]. The dog barked at the fox extract embeddings [SEP].'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = corpus[0]\n",
    "## Step 1: Adding the special token\n",
    "## Adding a CLS is simple\n",
    "sample_sentence = \"[CLS] \"+sample_sentence\n",
    "sample_sentence\n",
    "## To add the SEP:\n",
    "split_sentence = sample_sentence.split('.')\n",
    "sample_sentence=\" [SEP].\".join(split_sentence)\n",
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'the',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'jumping',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'dog',\n",
       " '[SEP]',\n",
       " '.',\n",
       " 'the',\n",
       " 'dog',\n",
       " 'barked',\n",
       " 'at',\n",
       " 'the',\n",
       " 'fox',\n",
       " 'extract',\n",
       " 'em',\n",
       " '##bed',\n",
       " '##ding',\n",
       " '##s',\n",
       " '[SEP]',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To tokenize the text, BERT provides its own tokenizer\n",
    "## Which we already imported\n",
    "tokenized_sentence = tokenizer.tokenize(sample_sentence)\n",
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: Some words has been split into smaller subwords and characters. The <b>two hash signs</b> preceding some of these subwords are just the tokenizer’s way to denote that this subword or character is part of a larger word and preceded by another subword. So, for example, the ‘##bed’ token is separate from the ‘bed’ token; the first is used whenever the subword ‘bed’ occurs within a larger word and the second is used explicitly for when the standalone token ‘thing you sleep on’ occurs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why?\n",
    "BERT is created using WordPiece model, where WordPiece model generated a vocabulary that contains all English characters plus the ~30,000 most common words and subwords found in the English language corpus the model is trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tears',\n",
       " 'senate',\n",
       " '00',\n",
       " 'card',\n",
       " 'asian',\n",
       " 'agent',\n",
       " '1947',\n",
       " 'software',\n",
       " '44',\n",
       " 'draw',\n",
       " 'warm',\n",
       " 'supposed',\n",
       " 'com',\n",
       " 'pro',\n",
       " '##il']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[4000:4015]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1996,\n",
       " 4248,\n",
       " 2829,\n",
       " 4419,\n",
       " 8660,\n",
       " 2058,\n",
       " 1996,\n",
       " 13971,\n",
       " 3899,\n",
       " 102,\n",
       " 1012,\n",
       " 1996,\n",
       " 3899,\n",
       " 17554,\n",
       " 2012,\n",
       " 1996,\n",
       " 4419,\n",
       " 14817,\n",
       " 7861,\n",
       " 8270,\n",
       " 4667,\n",
       " 2015,\n",
       " 102,\n",
       " 1012]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To convert the tokens into Vocab Indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]      :   101    \n",
      "the        :   1996   \n",
      "quick      :   4248   \n",
      "brown      :   2829   \n",
      "fox        :   4419   \n",
      "jumping    :   8660   \n",
      "over       :   2058   \n",
      "the        :   1996   \n",
      "lazy       :  13971   \n",
      "dog        :   3899   \n",
      "[SEP]      :   102    \n",
      ".          :   1012   \n",
      "the        :   1996   \n",
      "dog        :   3899   \n",
      "barked     :  17554   \n",
      "at         :   2012   \n",
      "the        :   1996   \n",
      "fox        :   4419   \n",
      "extract    :  14817   \n",
      "em         :   7861   \n",
      "##bed      :   8270   \n",
      "##ding     :   4667   \n",
      "##s        :   2015   \n",
      "[SEP]      :   102    \n",
      ".          :   1012   \n"
     ]
    }
   ],
   "source": [
    "for tup in zip(tokenized_sentence, indexed_tokens):\n",
    "    # Spacing can be added in formatted text using :<and size of spacing\n",
    "    print('{:<10} :{:^10}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "## Now we need to assign segment ID to tokens\n",
    "segments_ids = [1] * len(tokenized_sentence)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to convert the data we have into torch tensors, and then\n",
    "# Load the model\n",
    "torch_tensor = torch.tensor([indexed_tokens])\n",
    "segment_tensor = torch.tensor([segments_ids])\n",
    "\n",
    "model=BertModel.from_pretrained('bert-base-uncased',\n",
    "                                output_hidden_states=True) \n",
    "## output_hidden_states tells the model to return all hidden states\n",
    "# Put the model in \"evaluation\" mode [feed-forward operation]\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produce from the 12 layers. \n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(torch_tensor, segment_tensor)\n",
    "\n",
    "\n",
    "    # Because output_hidden_states is set to true, the third item will be hidden\n",
    "    # states from all layers, different configurations could be used when\n",
    "    # calling from_pretrained\n",
    "    hidden_states = outputs[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 25\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "# Understanding the output\n",
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[0]))\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[0][0]))\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[0][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conclusion: You can make use of a torch of size [25, 13, 768 ]\n",
    "So, for each token, ( 13,768) vector can represent it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
      "         [-0.4367,  0.5360, -0.0514,  ..., -0.0397,  0.6783, -0.5318],\n",
      "         [ 0.0764, -1.3345, -0.1239,  ..., -0.5126,  1.4597, -0.7255],\n",
      "         ...,\n",
      "         [-0.4762, -0.0660,  0.4777,  ...,  0.0764, -0.2680,  0.1501],\n",
      "         [-0.2840,  0.2271,  0.0111,  ..., -0.1397,  0.0289, -0.2636],\n",
      "         [-0.3635,  0.4525, -0.2429,  ...,  0.5196,  0.5170,  0.5195]]])\n"
     ]
    }
   ],
   "source": [
    "print(hidden_states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
